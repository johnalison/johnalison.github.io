<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2026-03-01 Sun 04:41 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>TechnoOptimism</title>
<meta name="generator" content="Org Mode" />
<link rel='stylesheet' type='text/css' href='/style.css'/>
<script src='/fix-tables.js' defer='defer'></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">TechnoOptimism</h1>
<p>
Very good.
</p>

<p>
<a href="https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html">https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html</a>
</p>

<ul class="org-ul">
<li>it really is the case that version N of our civilization's technology causes a problem, and version N+1 fixes it. However, this does not happen automatically, and requires intentional human effort</li>

<li>AI is: it's a new type of mind that is rapidly gaining in intelligence, and it stands a serious chance of overtaking humans' mental faculties and becoming the new apex species on the planet.  The class of things in that category is much smaller: we might plausibly include humans surpassing monkeys, multicellular life surpassing unicellular life, the origin of life itself, and perhaps the Industrial Revolution, in which machine edged out man in physical strength. Suddenly, it feels like we are walking on much less well-trodden ground.</li>
</ul>

<p>
<a href="AI.html#ID-6A1CFC4C-2DCB-4EDC-B5F1-167AC7DA2426">AI</a>
</p>

<ul class="org-ul">
<li>A big reason to be worried centers around instrumental convergence: for a very wide class of goals that a super-intelligent entity could have, two very natural intermediate steps that the AI could take to better achieve those goals are (i) consuming resources, and (ii) ensuring its safety.</li>

<li>my basic fear is that the same kinds of managerial technologies that allow OpenAI to serve over a hundred million customers with 500 employees will also allow a 500-person political elite, or even a 5-person board, to maintain an iron fist over an entire country.</li>

<li>The quest to make humanity a multi-planetary civilization can also be viewed from a d/acc perspective: having at least a few of us live self-sufficiently on other planets can increase our resilience against something terrible happening on Earth. Even if the full vision proves unviable for the time being, the forms of self-sufficient living that will need to be developed to make such a project possible may well also be turned to help improve our civilizational resilience on Earth.</li>

<li>It is generally understood among security professionals that the current state of computer security is pretty terrible. That said, it's easy to understate the amount of progress that has been made. Hundreds of billions of dollars of cryptocurrency are available to anonymously steal by anyone who can hack into users' wallets, and while far more gets lost or stolen than I would like, it's also a fact that most of it has remained un-stolen for over a decade.</li>
</ul>

<p>
<a href="Crypto.html#ID-59F44L4-1LM2-4PP4-9P89-P75P961768LN">Crypto</a>
</p>

<ul class="org-ul">
<li>out of all the things that we have known and seen in our universe, we, humans, are the brightest star. We are the one thing that we know about that, even if imperfectly, sometimes make an earnest effort to care about "the good", and adjust our behavior to better serve it.</li>
</ul>

<p>
<a href="WhoWeAre.html#ID-B75D0E27-3053-4565-AC82-DB4B933C52C0">WhoWeAre</a>
</p>
</div>
<div class="backlinks">
<h2>Backlinks</h2>
<ul>
  <li><a href="Blogs.html">Blogs</a></li>
</ul>
</div>
</body>
</html>
