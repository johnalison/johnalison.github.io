<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2026-03-01 Sun 04:40 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AutomatedVisualInspectionOFHGCSensors</title>
<meta name="generator" content="Org Mode" />
<link rel='stylesheet' type='text/css' href='/style.css'/>
<script src='/fix-tables.js' defer='defer'></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">AutomatedVisualInspectionOFHGCSensors</h1>
<p>
Over all the paper reads very well and looks like it will be an important part of the HGC QA, congratulations.
   (I hope this can be easily adopted to the module QA/QC, I guess so)
</p>

<p>
General comments:
</p>

<p>
-) p3: "This work presents a deep learning-based pre-selection algorithm (PSA) that fully automates the VI while also reducing the bias."
</p>

<p>
Was it actually demonstrated anywhere that this procedure reduces the bias? Was this quantified? If, should add discussion to the paper.
Otherwise, these statements should be qualified. "We believe this procedure reduces that expected from human bias etc."
</p>

<p>
Same comment applies to p16:  "The developed automated VI is standardized and less biased,"
</p>

<p>
-) p5: Paragraph that starts, "Unfortunately, &#x2026; "
   After reading all of this is not clear what is actually being used for this project.
   I gathered from above that R-CNN is not used. This paragraph discusses both fast-R-CNN and YOLO.
   I think this paragraph should end with a clear statement of what is being used below.
</p>

<p>
-) Section 3.4: Again I'm confused as to how the architecture describes here maps on to the discussion on p5.
</p>

<p>
-) p5: eq 3) and 4) which loss function is actually used in this work? Text unclear. 
</p>

<p>
-) Table 1 Worth adding a column for the AE training? 
</p>

<p>
-) Section 4) "2,052,240 patches from 5,030 whole images."
</p>
<ul class="org-ul">
<li>Where did these images come from? I thought we only had 50 sensors? Should clarify.</li>

<li>Also how was the ground truth of all these patches labeled ? I assume not with human inspection. Should clarify.</li>
</ul>

<p>
-) Table 4: Why are the numbers in the "score original" column different from those shown in table 2?
</p>

<p>
Minor:
-)  p3: "accepted or rejected by the inspector" &#x2013;&gt; "accepted or rejected by the human inspector"
</p>

<p>
-)  Sentence fragment: p5 "While self-supervised anomaly detection can be implemented using AEs, which are composed of two neural networks. "
</p>

<p>
-) Figure 3: Images seem out of order.
   Would recommend (from L to R top to bottom) Patching-&gt;Background-&gt;AE -&gt; classier
   Which I believe is the order in which they are applied.
</p>

<p>
-) Suggest that the list on p7 be written as a paragraph in complete sentences.
</p>

<p>
-) "The AE can be interpreted as a data pre-processing step that makes the subsequent anomaly detection"
    -&gt;
    "The AE can be interpreted as a data pre-processing step that makes the subsequent anomaly detection and classification"
</p>
</div>
</body>
</html>
