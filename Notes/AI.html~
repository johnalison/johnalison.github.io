<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2026-03-01 Sun 04:42 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AI</title>
<meta name="generator" content="Org Mode" />
<link rel='stylesheet' type='text/css' href='/style.css'/>
<script src='/fix-tables.js' defer='defer'></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">AI</h1>
<p>
<a href="AI-and-creating-our-own-Gods.html#ID-9823330F-5A69-4C46-A5E2-F72552D89364">AI-and-creating-our-own-Gods</a>
</p>

<p>
<a href="Computer As Source of Current Historical Revolution.html#ID-BBF720C5-7845-4025-A784-76DB41833D77">Computer As Source of Current Historical Revolution</a>
</p>

<p>
<a href="AI Most Pressing Issue of our Time.html#ID-36ACFF11-7D25-4CA6-AD86-7BF8CD805915">AI Most Pressing Issue of our Time</a>
</p>

<p>
<a href="Machine Learning is bottom up programing.html#ID-36D16F46-4AE3-48E3-B600-DB68E275FEC8">Machine Learning is bottom up programing</a>
</p>


<div id="outline-container-org550af6d" class="outline-2">
<h2 id="org550af6d">Thoughts</h2>
<div class="outline-text-2" id="text-org550af6d">
<ul class="org-ul">
<li><p>
With trying to develop AI we are trying — racing— to create actual, no-bullshit Gods and almost no one is talking about it.  
</p>

<p>
&gt; Its also not at all clear we will have much control over what kind
  of gods we create, and the consensus among experts is that it is
  something we are likely to do in the next 50-100 years and only
  get one shot at. Seems likely to lead to immortality or
  extinction.
</p>

<p>
&gt; But, How much do people spend talking about the fact that soon they
  will spend the rest of eternity not existing ?
</p></li>

<li><p>
How much smarter than humans can something get ? 
</p>

<p>
&gt; With narrow intelligence its clear there is a lot of
  room. General Intelligence its not obvious, eg: could asymptotic
  with humans being close to the max.  However even if “only” as
  smart as humans, AI will still be 10<sup>6</sup> times faster and have vast
  improvements in a wide range of narrow intelligence.
</p></li>

<li><p>
AI is a tragedy of the commons: 
</p>

<p>
&gt; Globally want to take our time with AI (huge potential
  downside). Personally, (without radical longevity) I want to
  accelerate AU b/c the downside of not getting AI and dying is
  (almost certainly) the same as getting bad AI.
</p></li>

<li>Like Elons response: Try to become the AI. Requires increasing bandwidth via neural-link.</li>

<li>We tend to use logic and reason after the fact to justify our decisions to ourselves and others. (What does this say about "interpretable AI"?)</li>
</ul>


<ul class="org-ul">
<li>Great podcase with Elizer Yudokowsky
<ul class="org-ul">
<li>Crazy to think that the AI can be boxed in.</li>
<li>Fire alarms are to get people to act as if its an emergency (not there to detect smoke) "There are no fire alarms for general AI"</li>
<li>The big story about alpha-go was not alpha-go beating the best go player, it was about alpha-0 beating the work class AI engineers.</li>
</ul></li>
</ul>
</div>
</div>
</div>
</body>
</html>
